# Source Code Development Instructions

This directory contains the main Python source code for the ticker-converter application. Follow these instructions for consistent, maintainable code development.

## Directory Purpose

The `/src/` directory houses all production Python code including:
- **CLI operations and user interfaces**
- **Core business logic and data processing**
- **Application setup and teardown procedures**
- **Modular components for data ingestion and transformation**

## Development Guidelines

### Code Organization

**Module Structure**:
```
src/ticker_converter/
├── __init__.py              # Package initialization
├── cli_ingestion.py         # Command-line interface
├── config.py               # Configuration management
├── run_api.py              # API server startup
├── api/                    # API endpoint definitions
├── api_clients/            # External API integration
├── data_ingestion/         # Data fetching and processing
└── data_models/            # Pydantic models and validation
```

### Implementation Standards

**Before adding new functionality**:
1. **Check existing modules** for similar functionality to avoid duplication
2. **Read directory README** to understand module organization
3. **Follow established patterns** for imports, error handling, and logging
4. **Implement comprehensive tests** in corresponding `/tests/unit/` structure

### Code Quality Requirements

**Every function must have**:
- **Type hints** for all parameters and return values
- **Comprehensive docstrings** following Google/NumPy style
- **Error handling** with meaningful error messages
- **Logging** using lazy % formatting (not f-strings)

**Example function template**:
```python
def process_market_data(
    symbol: str, 
    start_date: datetime, 
    end_date: datetime
) -> MarketDataResult:
    """Process market data for specified symbol and date range.

    Args:
        symbol: Stock ticker symbol (e.g., 'AAPL')
        start_date: Beginning of date range for data collection
        end_date: End of date range for data collection
        
    Returns:
        MarketDataResult containing processed data and metadata
        
    Raises:
        ValidationError: If symbol format is invalid
        DataFetchError: If external API fails
        
    Example:
        >>> result = process_market_data('AAPL', date(2023,1,1), date(2023,12,31))
        >>> print(result.total_records)
        365
    """
    logger.debug("Processing market data for symbol: %s", symbol)

    try:
        # Implementation here
        pass
    except APIError as e:
        logger.error("Failed to fetch data for %s: %s", symbol, e)
        raise DataFetchError(f"Unable to process {symbol}") from e
```

## Module-Specific Guidelines

### `/src/ticker_converter/api_clients/`
**Purpose**: External API integration and data fetching
- **Client classes** for each external API (Alpha Vantage, etc.)
- **Data processors** for API response transformation
- **Utilities** for common API operations
- **Exception handling** for API failures and rate limiting

### `/src/ticker_converter/data_ingestion/`
**Purpose**: Data collection, validation, and initial processing
- **Fetcher classes** for different data sources
- **Database managers** for data persistence
- **Orchestration** for coordinated data collection
- **Base classes** for common functionality

### `/src/ticker_converter/data_models/`
**Purpose**: Pydantic models for data validation and typing
- **API models** for external API responses
- **Market data models** for financial data structures
- **Validation rules** for data quality enforcement
- **Type definitions** for consistent typing

### `/src/ticker_converter/api/`
**Purpose**: FastAPI application and internal API endpoints
- **Endpoint definitions** for REST API
- **Database connections** and session management
- **API models** for request/response schemas
- **Dependencies** for common functionality

## Testing Integration

### Test Structure Alignment
Every module in `/src/` must have corresponding tests in `/tests/unit/`:
```
src/ticker_converter/data_ingestion/nyse_fetcher.py
tests/unit/data_ingestion/test_nyse_fetcher.py
```

### Test Requirements
- **Unit tests** for all public functions and methods
- **Integration tests** for database operations
- **Mock external dependencies** for reliable testing
- **Parameterized tests** for multiple input scenarios

## Error Handling Patterns

### Standard Exception Hierarchy
```python
# Custom exceptions in each module
class TickerConverterError(Exception):
    """Base exception for ticker converter operations."""
    pass

class DataFetchError(TickerConverterError):
    """Raised when external data fetching fails."""
    pass

class ValidationError(TickerConverterError):
    """Raised when data validation fails."""
    pass
```

### Error Handling Best Practices
- **Catch specific exceptions** rather than broad Exception
- **Log errors with context** using lazy formatting
- **Re-raise with meaningful messages** for user-facing operations
- **Include original exception** using `raise ... from e` pattern

## Configuration Management

### Configuration Sources
1. **Environment variables** for deployment-specific settings
2. **Configuration files** for default values
3. **Command-line arguments** for runtime overrides
4. **Constants** for immutable values

### Configuration Access Pattern
```python
from ticker_converter.config import settings

# Access configuration values
api_key = settings.alpha_vantage_api_key
database_url = settings.database_url
log_level = settings.log_level
```

## Logging Standards

### Logging Configuration
- **Module-level loggers**: `logger = logging.getLogger(__name__)`
- **Lazy formatting**: `logger.info("Processing %d records", count)`
- **Appropriate levels**: DEBUG, INFO, WARNING, ERROR, CRITICAL
- **No sensitive data**: Never log API keys, credentials, or PII

### Logging Examples
```python
import logging

logger = logging.getLogger(__name__)

# Good logging practices
logger.debug("Starting data ingestion for %s", symbol)
logger.info("Successfully processed %d records", record_count)
logger.warning("Rate limit approaching for API: %s", api_name)
logger.error("Failed to validate data: %s", validation_error)

# Avoid f-strings in logging
# Bad: logger.info(f"Processing {symbol}")
# Good: logger.info("Processing %s", symbol)
```

## Security Considerations

### Data Handling
- **Sanitize all external inputs** before processing
- **Use parameterized queries** for database operations
- **Validate data types and ranges** using Pydantic models
- **Handle sensitive data appropriately** (never log credentials)

### API Security
- **Use environment variables** for API keys and secrets
- **Implement rate limiting** for external API calls
- **Validate API responses** before processing
- **Handle authentication errors** gracefully

## Performance Guidelines

### Efficient Data Processing
- **Use generators** for large data sets
- **Implement batching** for database operations
- **Cache expensive operations** where appropriate
- **Profile performance** for optimization opportunities

### Memory Management
- **Process data in chunks** rather than loading everything into memory
- **Use appropriate data structures** for the task
- **Clean up resources** in finally blocks or context managers
- **Monitor memory usage** in long-running operations

## Integration Patterns

### Database Integration
- **Use context managers** for database connections
- **Implement transaction management** for data consistency
- **Handle connection failures** with retry logic
- **Use database migrations** for schema changes

### External API Integration
- **Implement exponential backoff** for retries
- **Handle rate limiting** gracefully
- **Cache responses** where appropriate
- **Monitor API health** and usage

## Refactoring Guidelines

Refer to `my_docs/guides/python_refactoring_guide.md` for detailed refactoring procedures. Key principles:

### Code Structure
- **Extract common functionality** into utility functions
- **Use inheritance** for shared behavior
- **Implement composition** over inheritance where appropriate
- **Apply SOLID principles** consistently

### Maintainability
- **Keep functions small** and focused
- **Use descriptive names** for variables and functions
- **Minimize dependencies** between modules
- **Document public interfaces** thoroughly

## Commit Guidelines

### Implementation Commits
```bash
git commit -m "feat: implement currency conversion validation"
```

### Refactoring Commits
```bash
git commit -m "refactor: extract common API client functionality"
```

### Quality Commits
```bash
git commit -m "style: fix pylint warnings in data_ingestion module"
```

## Quality Assurance

### Before Every Commit
```bash
# Format code
black src/

# Check linting
pylint src/

# Validate types
mypy src/

# Run tests
pytest tests/unit/

# Validate coverage
pytest --cov=src tests/
```

### Continuous Quality
- **Maintain Pylint score** at 10.00/10
- **Keep MyPy validation** clean
- **Ensure test coverage** above 50%
- **Follow PEP 8** consistently

# Repository Instructions for GitHub Copilot

This repository implements **ETL pipelines with Apache Airflow** for data engineering workflows. Follow these instructions for consistent, secure, and maintainable code generation.

## Project Context

**Type**: Data Engineering ETL Platform  
**Languages**: Python 3.11.12, SQL (PostgreSQL/SQLite)  
**Frameworks**: Apache Airflow, FastAPI, Pytest  
**Architecture**: Modular ETL with SQL-centric data transformations

## Development Workflow

### Project Management Process

When starting significant new work, follow the **structured project workflow**:

1. **Project Scoping**: Create detailed roadmap in `my_docs/TEMP_[PROJECT_NAME]_ROADMAP.md`
2. **Phase Breakdown**: 3-7 phases with measurable milestones
3. **Issue Creation**: GitHub issues for each deliverable using GitHub CLI
4. **Development Cycle**: 12-step process per issue (see workflow guide)

See `my_docs/guides/copilot_workflow_setup_guide.md` for complete workflow details.

### Development Cycle (Per GitHub Issue)

1. **Test Preparation**: Build/update tests before implementation
2. **Implementation**: Complete work per GitHub issue
3. **Verification**: Run tests to ensure functionality
4. **Initial Commit**: Professional implementation commit
5. **Refactoring**: Apply `my_docs/guides/python_refactoring_guide.md`
6. **Refactoring Commit**: Separate refactoring improvements commit
7. **Linting**: Fix whitespace, imports, style issues
8. **Static Analysis**: Pylint and MyPy validation
9. **Quality Assurance**: Full test suite execution
10. **Quality Commit**: Code quality improvements commit
11. **CI/CD Validation**: GitHub Actions via `act` CLI
12. **Pull Request**: Merge to dev and close issue

## Directory Organization

**CRITICAL**: Always read directory README files before creating new content.

### Primary Directories

- **`/dags/`**: Airflow DAGs and SQL queries (single source of truth for ALL SQL)
- **`/src/`**: Main Python source code and CLI operations
- **`/api/`**: FastAPI endpoints and external API clients
- **`/tests/`**: All testing infrastructure (mirrors `/src/` structure)
- **`/docs/`**: Authoritative project documentation
- **`/my_scripts/`**: Temporary development scripts (GITIGNORED - see strict usage rules)
- **`/my_docs/`**: Git-ignored working drafts and project roadmaps

### Directory README Compliance

**MANDATORY**: Before creating ANY new file or directory:

1. **Read the target directory's README.md** to understand usage rules
2. **Check subdirectory README files** for specific guidelines
3. **Verify no existing functionality** would be duplicated
4. **Follow established patterns** and naming conventions

### Special Directory Rules

#### `/my_scripts/` Directory
- **EXCLUSIVELY** for temporary testing and experimental scripts
- **GITIGNORED** - contents never committed to version control
- **NO REFERENCES** - no production code can import or reference anything here
- **NO DEPENDENCIES** - no other functions/methods/classes can depend on this content
- See `/my_scripts/README.md` for complete isolation requirements

### File Placement Protocol

1. **Read relevant directory README file**
2. **Check subdirectory README files** for specific usage guidelines
3. **Verify no existing functionality** to avoid duplication
4. **Place files by purpose**, not convenience
5. **Use established subdirectory patterns**
6. **Update documentation** when adding functionality

## Code Standards

### Python Requirements

- **PEP 8 compliance** with Black formatting (120-character line length)
- **Type hints** for all functions and classes
- **Comprehensive docstrings** for modules, classes, functions
- **Error handling** with meaningful messages
- **Logging** with lazy % formatting (not f-strings)
- **Modularity** with small, reusable functions

### Code Formatting Standards

- **Line length**: 120 characters maximum (configured in pyproject.toml)
- **Black formatter**: Use 120-character line length consistently
- **isort**: Use profile="black" with 120-character line length
- **Pylint**: max-line-length = 120

### Airflow DAG Standards

- **DAG IDs**: kebab-case and descriptive
- **Task IDs**: snake_case and action-oriented
- **Idempotency**: Safe for re-runs
- **Built-in operators** preferred over custom
- **Explicit dependencies** between tasks

### SQL Standards

- **snake_case** naming for all database objects
- **Parameterized queries** exclusively (prevent SQL injection)
- **Idempotent scripts** safe for re-execution
- **Clear formatting** with proper indentation and comments
- **Transaction management** for atomic operations

## Quality Requirements

### Testing

- **100% test pass rate** before any commit
- **Test coverage above 50%** (currently 54.27%)
- **Pytest framework** for all testing
- **No hardcoded test data** (use `/tests/fixtures/`)

### Code Quality Tools

```bash
# Required before any commit
black src/                 # Code formatting
pylint src/               # Static analysis
mypy src/                 # Type checking
pytest                    # Test execution
act                       # Local CI/CD validation
```

### Commit Standards

- **Implementation**: `feat: implement [feature description]`
- **Refactoring**: `refactor: improve [component] structure and clarity`
- **Quality**: `style: fix linting and type issues`

## Security Considerations

- **Input sanitization** for all external data
- **Parameterized queries** to prevent SQL injection
- **Environment variables** for secrets management
- **Least privilege** access control
- **No sensitive data** in logs
- **RBAC enforcement** across all systems

## Branch Management

- **Feature branches** from `dev` with descriptive names
- **Pull requests** mandatory for all merges
- **Format**: `feature/issue-[number]-[brief-description]`
- **Clean history** with logical commit progression

## Error Prevention

### Common Anti-Patterns to Avoid

- Creating duplicate functionality across directories
- Hardcoding values instead of using configuration
- Mixing SQL queries outside `/dags/sql/` directory
- Skipping tests or quality checks
- Using f-strings in logging statements
- Implementing without consulting directory READMEs
- **Violating 120-character line length** in any Python code
- **Placing permanent code in `/my_scripts/`** (temporary only)
- **Creating dependencies on `/my_scripts/` content** from production code
- **Ignoring subdirectory README files** and their specific usage rules

### Required Validations

- **Directory README consultation** before any file creation
- **Subdirectory README compliance** - check all README files in target directories
- **Existing functionality check** to prevent duplication
- **120-character line length** enforcement across all Python code
- **Test coverage maintenance** above 50%
- **Security consideration** for financial data
- **Documentation updates** for new features
- **Strict `/my_scripts/` isolation** - no production dependencies

## Integration Requirements

### GitHub CLI Usage

```bash
gh issue list --label "in-progress"
gh issue create --title "[Title]" --body "[Description]" --label "[labels]"
gh pr create --title "[Title]" --body "[Description]"
```

### Local Development Setup

```bash
pip install -e .[dev]     # Install with dev dependencies
airflow db migrate        # Initialize Airflow database
pytest                    # Validate test environment
```

## Documentation Standards

- **Update README files** when changing directory structure
- **Reference existing docs** in `/docs/` before creating new documentation
- **Link to guides** in `my_docs/guides/` for detailed procedures
- **Maintain consistency** with established documentation patterns

## Success Criteria

- All tests pass with coverage above 50%
- Zero linting violations (Black, Pylint, MyPy)
- Successful CI/CD pipeline execution
- Security best practices maintained
- Directory organization preserved
- Documentation kept current

For detailed workflow procedures, see:
- `my_docs/guides/copilot_workflow_setup_guide.md`
- `my_docs/guides/python_refactoring_guide.md`
- `my_docs/guides/GIT_WORKFLOW.md`
